---
title: "SSwAB-IT Phase 1 Analysis"
author: "Tim Vigers"
date: "today"
date-format: long
format:
  html:
    toc: true
    toc-depth: 5
    toc-float: true
    code-fold: true
    self-contained: true
    fig-cap-location: top
    page-layout: full
    theme:
      light: flatly
      dark: darkly

editor: source
---

```{r setup}
#| include: false
library(tidyverse)
library(gtsummary)
library(redcapAPI)
library(irr)
library(gt)
library(caret)
```

```{r data cleaning}
#| include: false
# Import from REDCap
unlockREDCap(c(rcon = "SSwAB-IT (New)"),
  keyring = "API_KEYs",
  envir = 1,
  url = "https://redcap.ucdenver.edu/api/"
)
exportBulkRecords(list(db = rcon), envir = 1)
# Exclude
exclude <- c("01-030_W", "01-038_W", "02-0038", "02-0039", "04-001")
# Combine collection results
df <- full_join(db_cos_collection_results, db_sos_collection_results)
# Format
df <- df %>%
  select(
    record_id, redcap_data_access_group,
    staphylococcus_aureus_cos:other_result_cos,
    staphylococcus_aureus_sos:other_result_sos
  ) %>%
  filter(!record_id %in% exclude)
# Remove empty demographics rows
db_demographics <- db_demographics %>%
  filter(
    redcap_event_name == "Clinic Visit (Arm 1: Eligible)",
    !record_id %in% exclude
  )
# Excluded participants
db_medications <- db_medications %>% filter(!record_id %in% exclude)
# Combine race and ethnicity columns
races <- c(
  "American Indian or Alaskan Native", "Asian", "Hawaiian or Pacific Islander",
  "Black or African American", "White", "Unknown", "Other"
)
ethnicities <- c("Hispanic", "Non-Hispanic", "Unknown/Not Reported")
db_demographics$Race <- apply(db_demographics, 1, function(r) {
  w <- which(r[grep("race", names(r))] == "Checked")
  if (length(w) == 1) {
    return(races[w])
  } else if (length(w) > 1) {
    return("Multiple Races")
  } else if (length(w) == 0) {
    return(NA)
  }
})
db_demographics$Ethnicity <- apply(db_demographics, 1, function(r) {
  w <- which(r[grep("ethnicity", names(r))] == "Checked")
  if (length(w) == 1) {
    return(ethnicities[w])
  } else if (length(w) > 1) {
    return(paste(ethnicities[w], sep = "/"))
  } else if (length(w) == 0) {
    return(NA)
  }
})
# # Drop levels
# level_drop <- c("sex", "Race", "Ethnicity")
# db_demographics[, level_drop] <- lapply(
#   db_demographics[, level_drop],
#   function(c) {
#     droplevels(factor(c))
#   }
# )
# Add groups to other dataframes
db_medications <- left_join(db_medications,
  db_demographics %>% select(record_id, group),
  by = join_by(record_id)
)
# Bug list
bugs <- c(
  "staphylococcus_aureus", "haemophilus_influenza", "pseudomonas_aeruginosa",
  "pseudomonas_non_aero", "s_maltophilia", "burkholderia", "aspergillus", "ntm",
  "other"
)
bug_names <- c(
  "S. aureus", "H. influenza", "P. aeruginosa", "Pseudomonas non-aeruginosa",
  "S. maltophilia", "Burkholderia", "Aspergillus", "NTM", "Other"
)
# Convert yes/no to positive/negative
df[, paste0(bugs, "_cos")] <- lapply(df[, paste0(bugs, "_cos")], factor,
  levels = c("No", "Yes"), labels = c("Negative", "Positive")
)
df[, paste0(bugs, "_sos")] <- lapply(df[, paste0(bugs, "_sos")], factor,
  levels = c("No", "Yes"), labels = c("Negative", "Positive")
)
# Create overall columns (any bug detected in sample)
df$overall_cos <- apply(df, 1, function(r) {
  any(r[paste0(bugs, "_cos")] == "Positive")
})
df$overall_cos <- factor(df$overall_cos,
  levels = c(F, T), labels = c("Negative", "Positive")
)
df$overall_sos <- apply(df, 1, function(r) {
  any(r[paste0(bugs, "_sos")] == "Positive")
})
df$overall_sos <- factor(df$overall_sos,
  levels = c(F, T), labels = c("Negative", "Positive")
)
# Add overall to list
bugs <- c(bugs, "overall")
bug_names <- c(bug_names, "Overall")
bug_list <- as.list(bug_names)
names(bug_list) <- bugs
```

# Data cleaning

Participants 01-030_W, 01-038_W, 02-0038, 02-0039, and 04-001 were excluded from all analyses. Participants missing either the COS or SOS sample were excluded from agreement analyses, but retained in feasibility and other analyses.

# Demographics

```{r}
db_demographics %>%
  select(group, sex, Race, Ethnicity) %>%
  tbl_summary(by = group, label = list("sex" = "Sex")) %>%
  add_overall() %>%
  add_p(test = list(c("Race", "Ethnicity") ~ "fisher.test")) %>%
  separate_p_footnotes() %>%
  as_gt()
```

# Medications

```{r}
db_medications %>%
  select(group, azithromycin:please_specify_mucolytic) %>%
  select(
    -inhaled_colisitin_status, -inhaled_vancomycin_status,
    -other_inhaled_status, -please_specify_mucolytic
  ) %>%
  tbl_summary(by = group) %>%
  add_overall() %>%
  add_p() %>%
  separate_p_footnotes() %>%
  as_gt()
```

# Agreement

Cohen's kappa is interpreted analagously to a correlation coefficient, with -1 indicating perfect disagreement and 1 indicating perfect agreement. Tables with NaN and NAs indicate that all tests had the same values (i.e. all absent or all present).

| Cohen's Kappa | Interpretation         |
|---------------|------------------------|
| 0             | No agreement           |
| 0.10 - 0.20   | Slight agreement       |
| 0.21 - 0.40   | Fair agreement         |
| 0.41 - 0.60   | Moderate agreement     |
| 0.61 - 0.80   | Substantial agreement  |
| 0.81 - 0.99   | Near perfect agreement |
| 1             | Perfect agreement      |

Given a 2x2 table of the form

| SOS      | COS      | n |
|----------|----------|---|
| Negative | Negative | D |
| Positive | Negative | B |
| Negative | Positive | C |
| Positive | Positive | A |

the accuracy metrics are calculated as follows:

$Sensitivity=\frac{A}{A+C}$

$Specificity=\frac{D}{B+D}$

$Prevalence=\frac{A+C}{A+B+C+D}$

$PPV=\frac{sensitivity∗prevalence}{(sensitivity∗prevalence)+((1−specificity)∗(1−prevalence))}$

$NPV=\frac{specificity∗(1−prevalence)}{((1−sensitivity)∗prevalence)+((specificity)∗(1−prevalence))}$

$DetectionRate=\frac{A}{A+B+C+D}$

$DetectionPrevalence=\frac{A+B}{A+B+C+D}$

$BalancedAccuracy=\frac{sensitivity+specificity}{2}$

$Precision=\frac{A}{A+B}$

$Recall=\frac{A}{A+C}$

$F1=\frac{2∗precision∗recall}{precision+recall}$

```{r}
agreement <- function(bug, data = df) {
  cos <- paste0(bug, "_cos")
  sos <- paste0(bug, "_sos")
  d <- data[, c(cos, sos)]
  d <- d[complete.cases(d), ]
  # Agreement metrics
  c <- confusionMatrix((d[, sos]),
    reference = d[, cos], positive = "Positive", mode = "everything"
  )
  # Return
  return(list(two_by_two = c$table, accuracy = c$overall, metrics = c$byClass))
}
```

```{r}
l <- lapply(bugs, function(b) {
  a <- agreement(b)
  return(list(
    Accuracy = a$accuracy["Accuracy"],
    `Accuracy Lower Limit` = a$accuracy["AccuracyLower"],
    `Accuracy Upper Limit` = a$accuracy["AccuracyUpper"],
    Kappa = a$accuracy["Kappa"], `Mcnemar P Value` = a$accuracy["McnemarPValue"]
  ))
})
l <- data.frame(do.call(rbind, l), check.names = F)
l <- data.frame(lapply(l, as.numeric), check.names = F)
rownames(l) <- bug_names
gt(l, rownames_to_stub = T) %>% fmt_number(n_sigfig = 3)
```

```{r results='asis'}
invisible(lapply(names(bug_list), function(b) {
  cat("\n")
  cat("##", as.character(bug_list[b]))
  cat("\n")
  cos <- paste0(b, "_cos")
  sos <- paste0(b, "_sos")
  d <- df[, c(cos, sos)]
  d <- d[complete.cases(d), ]
  cat("\n")
  c <- confusionMatrix(d[, sos],
    reference = d[, cos], positive = "Positive", mode = "everything"
  )
  metrics <- data.frame(c$overall)
  metrics2 <- data.frame(c$byClass)
  cat("### 2x2 table")
  cat("\n")
  two_by_two <- data.frame(c$table)
  colnames(two_by_two) <- c("SOS", "COS", "n")
  print(gt(two_by_two))
  cat("\n")
  cat("### Metrics")
  cat("\n")
  print(gt(metrics, rownames_to_stub = T) %>%
    fmt_number(n_sigfig = 3) %>%
    tab_options(column_labels.hidden = TRUE))
  cat("\n")
  print(gt(metrics2, rownames_to_stub = T) %>%
    fmt_number(n_sigfig = 3) %>%
    tab_options(column_labels.hidden = TRUE))
  cat("\n")
}))
```

# Questions

1. Are we okay with calculating prevalence from the data for the PPV and NPV? Do these numbers seem pretty representative of what you'd expect in the population?
