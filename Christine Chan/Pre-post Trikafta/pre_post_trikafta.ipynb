{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85fa964c-c265-4b8d-bc08-0346a4893ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "wd = '/Volumes/PEDS/RI Biostatistics Core/Shared/Shared Projects/Vigers/CF/Christine Chan/Prepost Triakfta/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01787282-ae74-4a77-b4a8-543ec7b9d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "chco_dates = pd.read_csv(wd + 'Data_Cleaned/chco_trikafta_dates.csv')\n",
    "# Fix selected dates\n",
    "chco_dates.loc[chco_dates.MRN == 1053930,'Earliest Trikafta Date in PortCF'] = \"12/1/2019\"\n",
    "chco_dates.loc[chco_dates.MRN == 1695512,'Earliest Trikafta Date in PortCF'] = \"12/12/2019\"\n",
    "chco_dates.loc[chco_dates.MRN == 815274,'Earliest Trikafta Date in PortCF'] = \"12/13/2019\"\n",
    "chco_dates.loc[chco_dates.MRN == 1078408,'Earliest Trikafta Date in PortCF'] = \"3/9/2020\"\n",
    "chco_dates.loc[chco_dates.MRN == 899717,'Earliest Trikafta Date in PortCF'] = \"2/14/2020\"\n",
    "# CFRD only\n",
    "chco_dates = chco_dates.loc[chco_dates['CFRD yes=1'] == 1]\n",
    "# Remove those without Trikafta date\n",
    "chco_dates.dropna(subset = ['Earliest Trikafta Date in PortCF'],inplace = True)\n",
    "# Add glycemic data\n",
    "chco_a1c = pd.read_csv(wd + 'Data_Cleaned/chco_a1c_ogtt.csv')\n",
    "chco = pd.merge(chco_dates,chco_a1c,on = ['MRN'],how = 'left')\n",
    "# Add PFTs\n",
    "chco_pfts = pd.read_csv(wd + 'Data_Cleaned/chco_bmi_pft.csv')\n",
    "chco = pd.merge(chco,chco_pfts,on = ['MRN','Date'],how = 'outer')\n",
    "# # Add CGM\n",
    "# chco_cgm = pd.read_csv(wd + 'Data_Cleaned/chco_cgm.csv')\n",
    "# chco_cgm['CFF ID'] = [int(re.sub('_.*','',s)) for s in chco_cgm['subject_id']]\n",
    "# chco_cgm['Date'] = [re.sub(' .*','',s) for s in chco_cgm['date_cgm_placement']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c473e51e-3b62-42f0-b451-68de39e74051",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.merge(chco,chco_cgm,on = ['CFF ID','Date'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b0547855-d44f-4f94-9645-3427d7cbdaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRN</th>\n",
       "      <th>DOB</th>\n",
       "      <th>CFF ID</th>\n",
       "      <th>Earliest Trikafta Date in PortCF</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hispanic/Latinx</th>\n",
       "      <th>Genotypes1</th>\n",
       "      <th>Genotypes2</th>\n",
       "      <th>Pancreatic Status</th>\n",
       "      <th>...</th>\n",
       "      <th>CFRD yes=1</th>\n",
       "      <th>Date</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>OGTT Fasting</th>\n",
       "      <th>OGTT Two Hour</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>FVC</th>\n",
       "      <th>FEV1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>739231</td>\n",
       "      <td>5/16/99</td>\n",
       "      <td>1435570.0</td>\n",
       "      <td>1/7/20</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>F508del</td>\n",
       "      <td>R553X</td>\n",
       "      <td>Insufficient</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/26/19</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.3</td>\n",
       "      <td>73.6</td>\n",
       "      <td>25.68</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>899717</td>\n",
       "      <td>11/14/02</td>\n",
       "      <td>1471890.0</td>\n",
       "      <td>2/14/2020</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>F508del</td>\n",
       "      <td>F508del</td>\n",
       "      <td>Insufficient</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3/29/19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899717</td>\n",
       "      <td>11/14/02</td>\n",
       "      <td>1471890.0</td>\n",
       "      <td>2/14/2020</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>F508del</td>\n",
       "      <td>F508del</td>\n",
       "      <td>Insufficient</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5/18/20</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899717</td>\n",
       "      <td>11/14/02</td>\n",
       "      <td>1471890.0</td>\n",
       "      <td>2/14/2020</td>\n",
       "      <td>Female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>F508del</td>\n",
       "      <td>F508del</td>\n",
       "      <td>Insufficient</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/11/20</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.5</td>\n",
       "      <td>62.1</td>\n",
       "      <td>22.95</td>\n",
       "      <td>5.23</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905284</td>\n",
       "      <td>12/31/02</td>\n",
       "      <td>1490380.0</td>\n",
       "      <td>3/11/20</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>True</td>\n",
       "      <td>F508del</td>\n",
       "      <td>G542X</td>\n",
       "      <td>Insufficient</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/3/19</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>1057798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/5/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.4</td>\n",
       "      <td>55.9</td>\n",
       "      <td>18.81</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1078408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/26/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>22.74</td>\n",
       "      <td>3.41</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>1078408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>22.78</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1413821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/25/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.8</td>\n",
       "      <td>61.8</td>\n",
       "      <td>20.23</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>1413821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/29/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.1</td>\n",
       "      <td>65.4</td>\n",
       "      <td>21.33</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MRN       DOB     CFF ID Earliest Trikafta Date in PortCF     Sex  \\\n",
       "0     739231   5/16/99  1435570.0                           1/7/20    Male   \n",
       "1     899717  11/14/02  1471890.0                        2/14/2020  Female   \n",
       "2     899717  11/14/02  1471890.0                        2/14/2020  Female   \n",
       "3     899717  11/14/02  1471890.0                        2/14/2020  Female   \n",
       "4     905284  12/31/02  1490380.0                          3/11/20    Male   \n",
       "..       ...       ...        ...                              ...     ...   \n",
       "621  1057798       NaN        NaN                              NaN     NaN   \n",
       "622  1078408       NaN        NaN                              NaN     NaN   \n",
       "623  1078408       NaN        NaN                              NaN     NaN   \n",
       "624  1413821       NaN        NaN                              NaN     NaN   \n",
       "625  1413821       NaN        NaN                              NaN     NaN   \n",
       "\n",
       "          Race Hispanic/Latinx Genotypes1 Genotypes2 Pancreatic Status  ...  \\\n",
       "0    Caucasian           False    F508del      R553X      Insufficient  ...   \n",
       "1    Caucasian           False    F508del    F508del      Insufficient  ...   \n",
       "2    Caucasian           False    F508del    F508del      Insufficient  ...   \n",
       "3    Caucasian           False    F508del    F508del      Insufficient  ...   \n",
       "4    Caucasian            True    F508del      G542X      Insufficient  ...   \n",
       "..         ...             ...        ...        ...               ...  ...   \n",
       "621        NaN             NaN        NaN        NaN               NaN  ...   \n",
       "622        NaN             NaN        NaN        NaN               NaN  ...   \n",
       "623        NaN             NaN        NaN        NaN               NaN  ...   \n",
       "624        NaN             NaN        NaN        NaN               NaN  ...   \n",
       "625        NaN             NaN        NaN        NaN               NaN  ...   \n",
       "\n",
       "    CFRD yes=1     Date  HbA1c OGTT Fasting  OGTT Two Hour  Height  Weight  \\\n",
       "0          1.0  4/26/19    5.7          NaN            NaN   169.3    73.6   \n",
       "1          1.0  3/29/19    7.0          NaN            NaN     NaN     NaN   \n",
       "2          1.0  5/18/20    7.5          NaN            NaN     NaN     NaN   \n",
       "3          1.0  8/11/20    6.5          NaN            NaN   164.5    62.1   \n",
       "4          1.0  12/3/19    6.1          NaN            NaN     NaN     NaN   \n",
       "..         ...      ...    ...          ...            ...     ...     ...   \n",
       "621        NaN   8/5/20    NaN          NaN            NaN   172.4    55.9   \n",
       "622        NaN  4/26/21    NaN          NaN            NaN   156.5    55.7   \n",
       "623        NaN  8/27/21    NaN          NaN            NaN   156.1    55.5   \n",
       "624        NaN  3/25/20    NaN          NaN            NaN   174.8    61.8   \n",
       "625        NaN  1/29/21    NaN          NaN            NaN   175.1    65.4   \n",
       "\n",
       "       BMI   FVC  FEV1  \n",
       "0    25.68  4.97  4.29  \n",
       "1      NaN   NaN   NaN  \n",
       "2      NaN   NaN   NaN  \n",
       "3    22.95  5.23  3.94  \n",
       "4      NaN   NaN   NaN  \n",
       "..     ...   ...   ...  \n",
       "621  18.81  4.92  4.06  \n",
       "622  22.74  3.41  2.74  \n",
       "623  22.78  3.47  2.67  \n",
       "624  20.23  4.58  4.20  \n",
       "625  21.33  4.68  4.21  \n",
       "\n",
       "[626 rows x 22 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1256192c-df7a-42ac-ac17-ebad81f7d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function merge in module pandas.core.reshape.merge:\n",
      "\n",
      "merge(left: 'DataFrame | Series', right: 'DataFrame | Series', how: 'str' = 'inner', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), copy: 'bool' = True, indicator: 'bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      "    Merge DataFrame or named Series objects with a database-style join.\n",
      "    \n",
      "    A named Series object is treated as a DataFrame with a single named column.\n",
      "    \n",
      "    The join is done on columns or indexes. If joining columns on\n",
      "    columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "    on indexes or indexes on a column or columns, the index will be passed on.\n",
      "    When performing a cross merge, no column specifications to merge on are\n",
      "    allowed.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        If both key columns contain rows where the key is a null value, those\n",
      "        rows will be matched against each other. This is different from usual SQL\n",
      "        join behaviour and can lead to unexpected results.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    left : DataFrame\n",
      "    right : DataFrame or named Series\n",
      "        Object to merge with.\n",
      "    how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      "        Type of merge to be performed.\n",
      "    \n",
      "        * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "          preserve key order.\n",
      "        * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "          preserve key order.\n",
      "        * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "          join; sort keys lexicographically.\n",
      "        * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "          join; preserve the order of the left keys.\n",
      "        * cross: creates the cartesian product from both frames, preserves the order\n",
      "          of the left keys.\n",
      "    \n",
      "          .. versionadded:: 1.2.0\n",
      "    \n",
      "    on : label or list\n",
      "        Column or index level names to join on. These must be found in both\n",
      "        DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "        to the intersection of the columns in both DataFrames.\n",
      "    left_on : label or list, or array-like\n",
      "        Column or index level names to join on in the left DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the left DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    right_on : label or list, or array-like\n",
      "        Column or index level names to join on in the right DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the right DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    left_index : bool, default False\n",
      "        Use the index from the left DataFrame as the join key(s). If it is a\n",
      "        MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "        or a number of columns) must match the number of levels.\n",
      "    right_index : bool, default False\n",
      "        Use the index from the right DataFrame as the join key. Same caveats as\n",
      "        left_index.\n",
      "    sort : bool, default False\n",
      "        Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "        the order of the join keys depends on the join type (how keyword).\n",
      "    suffixes : list-like, default is (\"_x\", \"_y\")\n",
      "        A length-2 sequence where each element is optionally a string\n",
      "        indicating the suffix to add to overlapping column names in\n",
      "        `left` and `right` respectively. Pass a value of `None` instead\n",
      "        of a string to indicate that the column name from `left` or\n",
      "        `right` should be left as-is, with no suffix. At least one of the\n",
      "        values must not be None.\n",
      "    copy : bool, default True\n",
      "        If False, avoid copy if possible.\n",
      "    indicator : bool or str, default False\n",
      "        If True, adds a column to the output DataFrame called \"_merge\" with\n",
      "        information on the source of each row. The column can be given a different\n",
      "        name by providing a string argument. The column will have a Categorical\n",
      "        type with the value of \"left_only\" for observations whose merge key only\n",
      "        appears in the left DataFrame, \"right_only\" for observations\n",
      "        whose merge key only appears in the right DataFrame, and \"both\"\n",
      "        if the observation's merge key is found in both DataFrames.\n",
      "    \n",
      "    validate : str, optional\n",
      "        If specified, checks if merge is of specified type.\n",
      "    \n",
      "        * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "          left and right datasets.\n",
      "        * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "          dataset.\n",
      "        * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "          dataset.\n",
      "        * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A DataFrame of the two merged objects.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    merge_ordered : Merge with optional filling/interpolation.\n",
      "    merge_asof : Merge on nearest keys.\n",
      "    DataFrame.join : Similar method using indices.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Support for specifying index levels as the `on`, `left_on`, and\n",
      "    `right_on` parameters was added in version 0.23.0\n",
      "    Support for merging named Series objects was added in version 0.24.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [1, 2, 3, 5]})\n",
      "    >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [5, 6, 7, 8]})\n",
      "    >>> df1\n",
      "        lkey value\n",
      "    0   foo      1\n",
      "    1   bar      2\n",
      "    2   baz      3\n",
      "    3   foo      5\n",
      "    >>> df2\n",
      "        rkey value\n",
      "    0   foo      5\n",
      "    1   bar      6\n",
      "    2   baz      7\n",
      "    3   foo      8\n",
      "    \n",
      "    Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "    the default suffixes, _x and _y, appended.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "      lkey  value_x rkey  value_y\n",
      "    0  foo        1  foo        5\n",
      "    1  foo        1  foo        8\n",
      "    2  foo        5  foo        5\n",
      "    3  foo        5  foo        8\n",
      "    4  bar        2  bar        6\n",
      "    5  baz        3  baz        7\n",
      "    \n",
      "    Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "    appended to any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "    ...           suffixes=('_left', '_right'))\n",
      "      lkey  value_left rkey  value_right\n",
      "    0  foo           1  foo            5\n",
      "    1  foo           1  foo            8\n",
      "    2  foo           5  foo            5\n",
      "    3  foo           5  foo            8\n",
      "    4  bar           2  bar            6\n",
      "    5  baz           3  baz            7\n",
      "    \n",
      "    Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "    any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: columns overlap but no suffix specified:\n",
      "        Index(['value'], dtype='object')\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      "    >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      "    >>> df1\n",
      "          a  b\n",
      "    0   foo  1\n",
      "    1   bar  2\n",
      "    >>> df2\n",
      "          a  c\n",
      "    0   foo  3\n",
      "    1   baz  4\n",
      "    \n",
      "    >>> df1.merge(df2, how='inner', on='a')\n",
      "          a  b  c\n",
      "    0   foo  1  3\n",
      "    \n",
      "    >>> df1.merge(df2, how='left', on='a')\n",
      "          a  b  c\n",
      "    0   foo  1  3.0\n",
      "    1   bar  2  NaN\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      "    >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      "    >>> df1\n",
      "        left\n",
      "    0   foo\n",
      "    1   bar\n",
      "    >>> df2\n",
      "        right\n",
      "    0   7\n",
      "    1   8\n",
      "    \n",
      "    >>> df1.merge(df2, how='cross')\n",
      "       left  right\n",
      "    0   foo      7\n",
      "    1   foo      8\n",
      "    2   bar      7\n",
      "    3   bar      8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d26a9f24-5aba-4d80-ae28-0f11f58c1b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 9, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f3675d0-462b-4e68-bf36-08336d8de687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       9/4/20 12:39\n",
       "1      4/26/19 14:56\n",
       "2      6/15/20 10:12\n",
       "3      12/6/19 22:14\n",
       "4      6/22/20 11:06\n",
       "5      8/28/20 14:38\n",
       "6      11/26/19 0:12\n",
       "7        4/2/20 3:25\n",
       "8       6/26/20 0:07\n",
       "9      12/30/19 0:01\n",
       "10     10/24/19 0:02\n",
       "11     10/31/20 2:37\n",
       "12     2/28/20 13:32\n",
       "13       4/2/20 3:25\n",
       "14       1/7/20 0:00\n",
       "15     2/10/20 13:35\n",
       "16     12/6/19 12:09\n",
       "17      1/12/21 0:53\n",
       "18     8/12/20 10:21\n",
       "19     10/26/19 1:14\n",
       "20     7/14/20 15:26\n",
       "21     9/23/20 13:52\n",
       "22    10/23/19 16:29\n",
       "Name: date_cgm_placement, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chco_cgm['date_cgm_placement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f38b5-e4d9-4568-9ed0-c004a7f21cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
